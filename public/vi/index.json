[
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Đường ống dữ liệu thời gian thực (RealTime Data Pipeline) sử dụng AWS Kinesis, AWS Lambda, Amazon DynamoDB, Amazon S3 (Simple Storage Service).\nMục Tiêu và Giá Trị: Dự án \u0026ldquo;Đường Ống Dữ liệu Thời Gian Thực\u0026rdquo; đã được thiết kế để thu thập, xử lý và trực quan hóa dữ liệu từ các phương tiện di chuyển trên tuyến đường. Mục tiêu của dự án là tạo ra một hệ thống linh hoạt, đáng tin cậy và mở rộng có khả năng phân tích dữ liệu thời gian thực, từ đó mang lại giá trị quan trọng cho quản lý giao thông, phân tích dữ liệu đường xá và dự báo tình trạng giao thông.\nKế Hoạch Triển Khai: Dự án sẽ được triển khai theo từng bước, bắt đầu từ tạo dữ liệu mô phỏng với Visual Studio Code. Sau khi dữ liệu được tạo, nó sẽ được gửi đến luồng Amazon Kinesis để thu thập. Các hàm Lambda sẽ xử lý dữ liệu và lưu trữ nó vào Amazon DynamoDB. Dữ liệu cuối cùng sau khi đã qua xử lý sẽ được lưu trữ trên Amazon S3 và hiển thị trực quan qua trang web.\nSơ đồ dưới đây minh họa kiến trúc đường ống dữ liệu: Nội dung Giới thiệu Tạo accessKeys Khởi tạo Kinesis Tạo dữ liệu mô phỏng Khởi tạo các databases Khởi tạo các lambda function Kiểm tra Dọn dẹp tài nguyên "
},
{
	"uri": "/vi/5-databases/5.1-dynamodb/",
	"title": "Khởi tạo DynamoDB",
	"tags": [],
	"description": "",
	"content": "Khởi tạo DynamoDB Nhập DynamoDB ở thanh tìm kiếm service trên AWS Console sau đó chọn DynamoDB. 2. Chọn Create table\nTable name, điền Data-Kinesis.Partition key điền timestamp. Còn lại để mặc định. Chọn Create table Đợi khoảng 2 phút đến khi trạng thái chuyển thành Active là hoàn thành. "
},
{
	"uri": "/vi/5-databases/5.2-s3/",
	"title": "Khởi tạo S3",
	"tags": [],
	"description": "",
	"content": "Trước tiên, ta tạo role trong AIM Nhập S3 ở thanh tìm kiếm service trên AWS Console sau đó chọn S3. Chọn Create bucket. Bucket name nhập webanalytics-huannguyen. Bỏ chọn \u0026ldquo;Block all public access\u0026rdquo;. Sau đó tích chọn \u0026ldquo;I acknowledge that the current settings might result in this bucket and the objects within becoming public.\u0026rdquo;. Giữ nguyên các cấu hình mặc định khác. Chọn Create bucket. Chọn tab Properties vào kéo xuống cuối trang.\nTại phần Static website hosting, chọn Edit. Phần Static website hosting, chọn Enable. Sau đó lần lượt nhập index.html và error.html vào ô Index document và Error document. Cuối cùng chọn Save changes. Chọn tab Permissions. Sau đó, tại Bucket policy chọn Edit. Sao chép và dán đoạn mã sau. Tiếp theo, chọn Save changes\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Statement1\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::webanalytics-huannguyen/*\u0026#34; } ] } Lưu ý: phần Resource cần điền chính xác bucket chúng ta sử dụng.\nTiếp theo, chúng ta sử dụng Visual Studio Code để tạo file index.html với đoạn mã sau: \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Data Visualization with D3.js\u0026lt;/title\u0026gt; \u0026lt;!-- Import D3.js --\u0026gt; \u0026lt;script src=\u0026#34;https://d3js.org/d3.v6.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div style=\u0026#34;width: 80%; margin: auto;\u0026#34;\u0026gt; \u0026lt;!-- SVG element for drawing the chart --\u0026gt; \u0026lt;svg id=\u0026#34;dataChart\u0026#34;\u0026gt;\u0026lt;/svg\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Data table display --\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;Data Table\u0026lt;/h2\u0026gt; \u0026lt;table\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Timestamp\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Route\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Count\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody id=\u0026#34;dataTableBody\u0026#34;\u0026gt;\u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; // Function to fetch and process data from the data.json file async function fetchData() { const response = await fetch(\u0026#39;data.json\u0026#39;); const data = await response.json(); // Sort data by timestamp before rendering data.sort((a, b) =\u0026gt; new Date(a.timestamp) - new Date(b.timestamp)); return data; } // Initialize the chart and table async function initChart() { const data = await fetchData(); const width = 800; const height = 400; // Select the SVG element for the chart const svg = d3.select(\u0026#39;#dataChart\u0026#39;) .attr(\u0026#39;width\u0026#39;, width) .attr(\u0026#39;height\u0026#39;, height); // Create a list of timestamps from the data const timestamps = data.map(entry =\u0026gt; new Date(entry.timestamp)); // Create a list of route names from the data const routeNames = Array.from(new Set(data.map(entry =\u0026gt; entry.route))); // Define scaling for the x and y axes const xScale = d3.scaleTime() .domain(d3.extent(timestamps)) .range([60, width - 40]); const yScale = d3.scaleLinear() .domain([0, d3.max(data, d =\u0026gt; d.count)]) .range([height - 40, 20]); // Create data lines for each route for (let i = 0; i \u0026lt; routeNames.length; i++) { const routeData = data.filter(d =\u0026gt; d.route === routeNames[i]); // Define the line generator function const line = d3.line() .x((d, i) =\u0026gt; xScale(new Date(d.timestamp))) .y(d =\u0026gt; yScale(d.count)); // Draw the data line on the chart svg.append(\u0026#39;path\u0026#39;) .datum(routeData) .attr(\u0026#39;fill\u0026#39;, \u0026#39;none\u0026#39;) .attr(\u0026#39;stroke\u0026#39;, d3.schemeCategory10[i]) // Different color for each route .attr(\u0026#39;stroke-width\u0026#39;, 2) .attr(\u0026#39;d\u0026#39;, line); // Display data in the table const dataTableBody = d3.select(\u0026#39;#dataTableBody\u0026#39;); routeData.forEach(entry =\u0026gt; { dataTableBody.append(\u0026#39;tr\u0026#39;) .html(`\u0026lt;td\u0026gt;${entry.timestamp}\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;${entry.route}\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;${entry.count}\u0026lt;/td\u0026gt;`); }); // Add legend for each route svg.append(\u0026#39;circle\u0026#39;) .attr(\u0026#39;cx\u0026#39;, width - 100) .attr(\u0026#39;cy\u0026#39;, 20 + i * 20) .attr(\u0026#39;r\u0026#39;, 6) .attr(\u0026#39;fill\u0026#39;, d3.schemeCategory10[i]); svg.append(\u0026#39;text\u0026#39;) .attr(\u0026#39;x\u0026#39;, width - 90) .attr(\u0026#39;y\u0026#39;, 25 + i * 20) .attr(\u0026#39;font-size\u0026#39;, \u0026#39;12px\u0026#39;) .text(routeNames[i]); } // Add x and y axes const xAxis = d3.axisBottom(xScale) .ticks(5); const yAxis = d3.axisLeft(yScale) .ticks(5); svg.append(\u0026#39;g\u0026#39;) .attr(\u0026#39;transform\u0026#39;, `translate(40, ${height - 40})`) .call(xAxis); svg.append(\u0026#39;g\u0026#39;) .attr(\u0026#39;transform\u0026#39;, `translate(40, 0)`) .call(yAxis); // Add gridlines svg.append(\u0026#39;g\u0026#39;) .attr(\u0026#39;class\u0026#39;, \u0026#39;grid\u0026#39;) .attr(\u0026#39;transform\u0026#39;, `translate(40, 0)`) .call(d3.axisLeft(yScale).ticks(5).tickSize(-width + 60).tickFormat(\u0026#39;\u0026#39;)); svg.append(\u0026#39;g\u0026#39;) .attr(\u0026#39;class\u0026#39;, \u0026#39;grid\u0026#39;) .attr(\u0026#39;transform\u0026#39;, `translate(40, ${height - 40})`) .call(d3.axisBottom(xScale).ticks(5).tickSize(-height + 60).tickFormat(\u0026#39;\u0026#39;)); } // Call the initChart function to initialize the chart and table initChart(); // Automatically refresh the page every 10 seconds setInterval(() =\u0026gt; { location.reload(); }, 10000); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Upload file index.html vừa tạo lên S3: Sau khi upload file thành công. Ta quay lại tab Properties và kéo xuống cuối trang. Tại đây chúng ta sẽ thấy đường link của website. Click vào đường link. Website hiện thị như sau là thành công. Ghi chú: Hiện tại trong S3 vẫn chưa có dữ liệu nên trang web vẫn trống, chưa chứa nhiều thông tin.\n"
},
{
	"uri": "/vi/",
	"title": "Serverless Application",
	"tags": [],
	"description": "",
	"content": "Triển khai đường ống dữ liệu theo thời gian thực Tổng quan Trong bài workshop này, chúng ta sử dụng một số dịch vụ quan trọng của Amazon Web Services (AWS) để tạo nên một hệ thống thu thập, xử lý và trực quan hóa dữ liệu giao thông thời gian thực. Dưới đây là một giới thiệu về các dịch vụ được sử dụng trong dự án và khái niệm cũng như công dụng của mỗi dịch vụ:\nAmazon Kinesis:\nKhái Niệm: Amazon Kinesis là một dịch vụ thu thập, xử lý và truyền dữ liệu thời gian thực. Công Dụng: Trong dự án, Amazon Kinesis được sử dụng để nhận và thu thập dữ liệu từ các phương tiện đang di chuyển trên tuyến đường. Nó cho phép chúng ta xử lý dữ liệu thời gian thực và định dạng chuẩn hóa trước khi chuyển tiếp vào các bước xử lý tiếp theo. AWS Lambda:\nKhái Niệm: AWS Lambda là một dịch vụ tính toán \u0026ldquo;serverless\u0026rdquo; cho phép bạn thực hiện mã nguồn mà không cần phải quản lý máy chủ. Công Dụng: Trong đường ống dữ liệu, AWS Lambda được sử dụng để xử lý dữ liệu thu thập từ Kinesis. Mỗi lần dữ liệu được gửi đến, Lambda có thể thực hiện các xử lý như tính toán thống kê, chuyển đổi định dạng, lọc dữ liệu, hoặc thực hiện các phân tích phức tạp. Amazon DynamoDB:\nKhái Niệm: Amazon DynamoDB là một dịch vụ cơ sở dữ liệu NoSQL có khả năng mở rộng, sử dụng kiểu lưu trữ khóa và giá trị. Công Dụng: Dữ liệu sau khi đã qua xử lý bởi Lambda được lưu trữ vào Amazon DynamoDB. DynamoDB cung cấp tính năng lưu trữ hiệu suất cao và có khả năng mở rộng, phù hợp cho việc lưu trữ và truy vấn dữ liệu giao thông thời gian thực. Amazon S3 (Simple Storage Service):\nKhái Niệm: Amazon S3 là dịch vụ lưu trữ đám mây với khả năng mở rộng và tin cậy. Công Dụng: Dữ liệu đã qua xử lý hoàn toàn sẽ được lưu trữ vào Amazon S3. Dịch vụ này cho phép chúng ta lưu trữ dữ liệu trực quan hoá, như biểu đồ, đồ thị và bản đồ tương tác, để người dùng có thể truy cập và tìm hiểu dữ liệu một cách dễ dàng. Bằng cách kết hợp các dịch vụ trên, dự án \u0026ldquo;Đường Ống Dữ liệu Thời Gian Thực\u0026rdquo; tạo nên một hệ thống hoàn chỉnh từ việc thu thập dữ liệu thời gian thực tới xử lý và trực quan hóa.việc và thời gian triển khai quy trình ETL.\n"
},
{
	"uri": "/vi/6-lambda/6.1-role/",
	"title": "Tạo Role",
	"tags": [],
	"description": "",
	"content": "Trước tiên, ta tạo role trong AIM Nhập AIM ở thanh tìm kiếm service trên AWS Console sau đó chọn AIM. 2. Ở thanh điều hướng bên trái, chọn Rules Chọn Create role Chọn AWS service và Lambda. Sau đó nhấn Next. Lần lượt tìm kiếm với các từ khóa và tích chọn policy tương ứng:\nCloudWatch: CloudWatchFullAccess S3 : AmazonS3FullAccess DynamoDB: AmazonDynamoDBFullAccess Kinesis : AmazonKinesisFullAccess Lưu ý: Trong môi trường của bài thực hành, để đơn giản và tiện lợi, chúng ta sẽ sử dụng một vai trò (role) cho cả hai Lambda Function và trao quyền FullAccess trên tất cả các dịch vụ. Tuy nhiên, khi triển khai vào sản phẩm thực tế, chúng ta cần cấu hình từng vai trò với các chính sách (policy) đủ để đảm bảo tính an toàn và bảo mật.\nTrong tình huống thực tế, việc chia nhỏ vai trò và thiết lập các chính sách cụ thể sẽ giúp hạn chế quyền truy cập dựa trên nhiệm vụ và nguy cơ bảo mật. Điều này giúp bảo vệ tài nguyên của bạn khỏi truy cập trái phép và tiềm ẩn các rủi ro an ninh.\nSau khi thêm đủ policy, ta chọn Next.\nRole name điền RoleLab2. Kiểm tra lại và chọn Create role. "
},
{
	"uri": "/vi/2-accesskeys/",
	"title": "Khởi tạo Access Keys",
	"tags": [],
	"description": "",
	"content": "Khởi tạo Access Keys Trong workshop này, chúng ta sẽ cần tương tác với AWS bằng cách sử dụng CLI (Command Line Interface). Vì vậy, để thiết lập kết nối, chúng ta cần tạo Access Keys để sử dụng cho quá trình này.\nQuá trình khởi tạo: Tại trang console, chúng ta chọn tên tài khoản ở góc trên bên phải. Sau đó chọn Security credentials. Chọn Create access key. Đánh dấu tích vào ô \u0026ldquo;I understand creating a root access key is not a best practice, but I still want to create one.\u0026rdquo;. Sau đó chọn Create access key. Tại đây, thông tin Access Key - Secret access key được hiển thi. Chúng ta có thể tải về (Download .csv file). Sau đó chọn Save. Vậy là chúng ta đã khởi tạo xong.\n"
},
{
	"uri": "/vi/6-lambda/6.2-lambda1/",
	"title": "Tạo Lambda 1",
	"tags": [],
	"description": "",
	"content": "Các bước thực hiện chi tiết: Nhập Lambda ở thanh tìm kiếm service trên AWS Console sau đó chọn Lambda. Chọn Create function. Function name điền KinesisToDynamoDB. Runtime chọn Python 3.9. Tích chọn Use an existing role sau đó chọn role vừa khởi tạo ở phần trước RoleLab2. Cuối cùng, chọn Create function. Sao chép và dán đoạn mã sau. Sau đó nhấn Debloy.\nimport boto3 import binascii import json # Initialize DynamoDB resource dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table_name = \u0026#39;Data-Kinesis\u0026#39; # Replace with your DynamoDB table name table = dynamodb.Table(table_name) def lambda_handler(event, context): print(event) for record in event[\u0026#39;Records\u0026#39;]: payload = binascii.a2b_base64(record[\u0026#39;kinesis\u0026#39;][\u0026#39;data\u0026#39;]) data = json.loads(payload) # Store data in DynamoDB table response = table.put_item( Item={ \u0026#39;timestamp\u0026#39;: data[\u0026#39;timestamp\u0026#39;], \u0026#39;route\u0026#39;: data[\u0026#39;route\u0026#39;], \u0026#39;count\u0026#39;: data[\u0026#39;count\u0026#39;] } ) print(f\u0026#34;Stored data in DynamoDB: {response}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Data stored in DynamoDB\u0026#39;) } Kéo xuống cuối trang, chọn Add a layer. Chọn Specify an ARN. Điền arn:aws:lambda:ap-southeast-1:770693421928:layer:Klayers-p39-boto3:18. Sau đó nhần Verify và Add. Chọn Add trigger. Chọn Kinesis, sau đó chọn Kinesis stream ta đã tạo trước đó. Starting position chúng ta chọn Trim horizon. Tiếp theo, chọn Add. Đợi khoảng 1 phút, khi trạng thái chuyển thành Enabled. Vậy là ta đã cấu hình xong Lambda1. Chúng ta sẽ tiến hành kiểm tra khả năng hoạt động của nó. Mở Visual Studio Code, chạy file createData.py mà chúng ta đã tạo trước đó. Truy cập lại vào trang lambda 1, tại tab Monitor chúng ta chọn View CloudWatch logs.\nTại cửa sổ mới, chúng ta chọn log mới nhất. Nếu log chưa xuất hiện chúng ta đợi 1 phút và nhấn reload. Chúng ta có thể thấy không có thông báo lỗi (Error) xuất hiện. Chúng ta truy cập vào bảng DynamoDB Data-Kinesis đã tạo trước đó. Sau đó chọn Explore table items. Chúng ta có thể thấy dữ liệu gửi từ VS Code đã được lưu về trong bảng. "
},
{
	"uri": "/vi/3-kinesis/",
	"title": "Khởi tạo Kinesis",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ tiến hành khởi tạo một luồng dữ liệu trong Amazon Kinesis, tạo nền tảng cho việc thu thập và xử lý dữ liệu thời gian thực từ các nguồn khác nhau.\nCác bước thực hiện: Nhập Kinesis ở thanh tìm kiếm service trên AWS Console sau đó chọn Kinesis. Chọn Create data stream. Phần Dât stream name, chúng ta điền KinesisDataStream. Sau đó chọn Provisioned, nhập 1. Cuối cùng chọn Create data stream. Đợi khoảng 2 phút, trạng thái chuyển thành Active là hoàn thành. "
},
{
	"uri": "/vi/6-lambda/6.3-lambda2/",
	"title": "Tạo Lambda 2",
	"tags": [],
	"description": "",
	"content": "Các bước thực hiện chi tiết: Tương tự như tạo lambda 1, chúng ta truy cập vào trang dịch vụ Lambda và chọn Create function.\nFunction name điền DynamoDBToS3. Runtime chọn Python 3.9. Tích chọn Use an existing role sau đó chọn role vừa khởi tạo ở phần trước RoleLab2. Cuối cùng, chọn Create function.\nSao chép và dán đoạn mã sau. Sau đó nhấn Debloy. import boto3 import json from datetime import datetime, timedelta, timezone # Initialize DynamoDB and S3 clients dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) s3_client = boto3.client(\u0026#39;s3\u0026#39;) def get_data_from_dynamodb(start_time, end_time): # Retrieve all data from DynamoDB response = dynamodb.scan( TableName=\u0026#39;Data-Kinesis\u0026#39; ) # Filter data within the specified time range filtered_data = [] for item in response[\u0026#39;Items\u0026#39;]: timestamp = item[\u0026#39;timestamp\u0026#39;][\u0026#39;S\u0026#39;] count = item[\u0026#39;count\u0026#39;][\u0026#39;N\u0026#39;] route = item[\u0026#39;route\u0026#39;][\u0026#39;S\u0026#39;] if start_time \u0026lt;= timestamp \u0026lt;= end_time: filtered_data.append({ \u0026#34;timestamp\u0026#34;: timestamp, \u0026#34;count\u0026#34;: int(count), \u0026#34;route\u0026#34;: route }) return filtered_data def upload_json_to_s3(data): # Save data to a JSON file in memory json_data = json.dumps(data) # Upload the JSON file to Amazon S3 s3_client.put_object( Bucket=\u0026#39;webanalytics-huannguyen\u0026#39;, Key=\u0026#39;data.json\u0026#39;, # Path and filename on S3 Body=json_data.encode(\u0026#39;utf-8\u0026#39;) ) def lambda_handler(event, context): # Get current time and the time one hour ago in Vietnamese timezone (GMT+7) vn_timezone = timezone(timedelta(hours=7)) end_time = (datetime.now(vn_timezone)).strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) start_time = (datetime.now(vn_timezone) - timedelta(hours=1)).strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) # Get data from DynamoDB data = get_data_from_dynamodb(start_time, end_time) # Upload JSON data to Amazon S3 upload_json_to_s3(data) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Data updated and uploaded to S3 successfully.\u0026#39;) } Ghi chú: Đoạn mã trên thực hiện lấy dự liệu trước thời điểm hiện tại 1 giờ từ DynamoDB và lưu thành file data.json trong bucket S3\nKéo xuống cuối trang, chọn Add a layer. Chọn Specify an ARN. Điền arn:aws:lambda:ap-southeast-1:770693421928:layer:Klayers-p39-boto3:18. Sau đó nhần Verify và Add. Chọn Add trigger. Chọn DynamoDB, sau đó chọn DynamoDB table ta đã tạo trước đó. Starting position chúng ta chọn Latest. Tiếp theo, chọn Add. Đợi khoảng 1 phút, khi trạng thái chuyển thành Enabled. "
},
{
	"uri": "/vi/4-ide/",
	"title": "Tạo dữ liệu mô phỏng",
	"tags": [],
	"description": "",
	"content": "Trong workshop lần này, do chúng ta không có dữ liệu trực tiếp từ các cảm biến gửi về, nên chúng ta sẽ sử dụng Visual Studio Code để tạo dữ liệu mô phỏng về số lượng xe lưu thông trên bốn tuyến đường khác nhau: \u0026ldquo;Route A,\u0026rdquo; \u0026ldquo;Route B,\u0026rdquo; \u0026ldquo;Route C,\u0026rdquo; và \u0026ldquo;Route D.\u0026rdquo; Sau đó, chúng ta sẽ gửi dữ liệu này đến luồng dữ liệu Kinesis để tiếp tục quá trình xử lý và phân tích.\nGhi chú: Dữ liệu gửi đi dưới định dạng json như sau: { \u0026ldquo;timestamp\u0026rdquo;: \u0026ldquo;2023-08-15 19:22:02\u0026rdquo;, \u0026ldquo;route\u0026rdquo;: \u0026ldquo;Route B\u0026rdquo;, \u0026ldquo;speed\u0026rdquo;: 75 }\nCác bước thực hiện: Phần 1- Gửi dữ liệu. Mở Visual Studio Code và tạo file mới createData.py. Sau đó mở Terminal để thực hiện kết nối với AWS thông qua Access Key đã tạo từ phần trước. Sử dụng lệnh aws configure Lần lượt điền Access Key - Secret access key - region name - output format Access Key - Secret access key: lấy thông tin từ phần 2. region name: region mà bạn đang làm workshop ap-southeast-1 output format: json 2. Sao chép và dán đoạn mã sau vào file vừa tạo.\nimport random import json import boto3 import time from datetime import datetime # Create a connection to Kinesis Data Streams client = boto3.client(\u0026#39;kinesis\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) stream_name = \u0026#39;demo\u0026#39; # List of routes routes = [\u0026#34;Route A\u0026#34;, \u0026#34;Route B\u0026#34;, \u0026#34;Route C\u0026#34;, \u0026#34;Route D\u0026#34;] # Function to generate simulated traffic events for all routes def generate_traffic_event(route): count = random.randint(30, 100) # Number of vehicles on the route, 30-100 timestamp = datetime.now().strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) event_data = { \u0026#39;timestamp\u0026#39;: timestamp, \u0026#39;route\u0026#39;: route, \u0026#39;count\u0026#39;: count } return json.dumps(event_data) # Send simulated data to the data stream for all routes while True: for route in routes: event_data = generate_traffic_event(route) response = client.put_record( StreamName=stream_name, Data=bytes(event_data, \u0026#39;utf-8\u0026#39;), PartitionKey=\u0026#39;123\u0026#39; ) print(f\u0026#34;Sent: {event_data}\u0026#34;) time.sleep(1) time.sleep(30) Chọn biểu tượng hình tam giác ở góc trên bên phải (Run code) để thực thi. Sau đó, tại cửa sổ terminal chúng ta nhập được thông báo dữ liệu gửi đi. Phần 2 - Kiểm tra dữ liệu có gửi đến Kinesis: Mở dịch vụ Kinesis. Chọn Data Stream chúng ta đã tạo trước đó. Tại tab Data viewer. Shard chọn Shardld-00000000000, Starting position chọn Trim horizon. Cuối cùng chọn Get records. Tại đây, chúng ta thấy 4 dòng dữ liệu mà lúc nãy đã gửi đi. Vậy là Kinesis đã nhận được dữ liệu.\n"
},
{
	"uri": "/vi/5-databases/",
	"title": "Khởi tạo các databases",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, chúng ta sẽ tận dụng hai dịch vụ lưu trữ quan trọng từ Amazon Web Services (AWS): Amazon DynamoDB và Amazon S3.\nDynamoDB dùng để lưu trữ dữ liệu đã qua xử lý từ Amazon Kinesis. Nó là một cơ sở dữ liệu NoSQL có khả năng mở rộng, cho phép lưu trữ và truy vấn dữ liệu một cách hiệu quả, đồng thời hỗ trợ quản lý dữ liệu phức tạp và phân tích dữ liệu trong thời gian thực.\nS3 dùng để lưu trữ dữ liệu đã qua xử lý và trực quan hóa từ dự án. Amazon S3 là dịch vụ lưu trữ đám mây với khả năng mở rộng, cho phép lưu trữ các loại dữ liệu như tệp tin, hình ảnh, video và dữ liệu cấu trúc. Dữ liệu này có thể được truy cập và chia sẻ dễ dàng thông qua các liên kết và tích hợp với các dịch vụ và ứng dụng khác trên nền tảng AWS.\n"
},
{
	"uri": "/vi/6-lambda/",
	"title": "Khởi tạo các lambda function",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ tiến hành ba bước quan trọng để xây dựng dòng chảy dữ liệu thời gian thực:\nKhởi tạo Vai Trò (Role) cho Lambda Function: Trước hết, chúng ta sẽ khởi tạo một vai trò (role) đặc biệt cho các Lambda Function. Vai trò này sẽ cung cấp các quyền cần thiết để Lambda có thể tương tác với các dịch vụ khác như Kinesis, DynamoDB và S3 một cách an toàn và bảo mật.\nCấu hình Lambda 1: Gửi Dữ Liệu từ Kinesis đến DynamoDB: Bước tiếp theo, chúng ta sẽ cấu hình Lambda Function đầu tiên. Lambda này sẽ thực hiện nhiệm vụ đưa dữ liệu từ luồng Kinesis mà chúng ta đã tạo trước đó và lưu trữ vào DynamoDB. Quá trình này sẽ xử lý và chuẩn hóa dữ liệu để tiện cho việc truy vấn và phân tích sau này.\nCấu hình Lambda 2: Gửi Dữ Liệu từ DynamoDB đến S3 và Lưu Dưới Dạng JSON: Cuối cùng, chúng ta sẽ cấu hình Lambda Function thứ hai. Lambda này sẽ lấy dữ liệu đã được xử lý và lưu trữ trong DynamoDB và gửi chúng đến Amazon S3. Dữ liệu sẽ được lưu dưới dạng các tệp tin JSON trong S3, tạo nền tảng cho việc trực quan hóa và phân tích dữ liệu.\nBa bước trên cùng nhau tạo nên một quy trình hoàn chỉnh từ việc thu thập dữ liệu thời gian thực tới lưu trữ và trực quan hóa.\nNội dung Tạo Role Tạo Lambda 1 Tạo Lambda 2 "
},
{
	"uri": "/vi/7-test/",
	"title": "Kiểm tra kết quả ",
	"tags": [],
	"description": "",
	"content": " Bắt đầu bằng việc mở Visual Studio Code (VS Code) và chạy tệp createData.py. Tệp này chứa mã để tạo dữ liệu mô phỏng cho việc thử nghiệm. Bằng cách chạy mã này, chúng ta sẽ tạo ra các dữ liệu liên quan đến lưu lượng giao thông trên các tuyến đường.\nTiếp theo, hãy mở trang web mà chúng ta đã cấu hình trước đó. Trang web này sẽ giúp chúng ta trực quan hóa dữ liệu một cách đồ họa và dễ hiểu. Bạn sẽ thấy rằng sau khi dữ liệu đã được gửi đi từ VS Code, trang web sẽ tự động cập nhật và hiển thị dữ liệu được trực quan hóa.\nViệc này cho phép bạn thấy rõ quá trình từ việc tạo dữ liệu mô phỏng đến việc trực quan hóa dữ liệu thời gian thực thông qua các dịch vụ của AWS mà chúng ta đã cấu hình.\nKết quả sau 10 phút chạy liên tục. "
},
{
	"uri": "/vi/8-terminate/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "S3 Truy cập vào S3 chọn bucket S3 đã khởi tạo trong bài lab. Sau đó chọn Empty Nhập permanently delete và chọn Empty. Chọn bucket S3 đã khởi tạo trong bài lab. Sau đó chọn Delete Nhập tên bucket webanalytics-huannguyen. Sau đó chọn Delete bucket Lambda Truy cập vào Lambda chọn các Lambda đã khởi tạo trong bài lab. Sau đó chọn Action \u0026ndash;\u0026gt; Delete Nhập delete sau đó chọn Delete. DynamoDB Truy cập vào DynamoDB chọn các bảng đã khởi tạo trong bài lab. Sau đó chọn Delete Nhập confirm sau đó chọn Delete. Kinesis Truy cập vào Kinesis chọn Data stream đã khởi tạo trong bài lab. Sau đó chọn Action \u0026ndash;\u0026gt; Delete Nhập delete sau đó chọn Delete.\nRole Truy cập vào AIM chọn tab Role, sau đó chọn Role đã khởi tạo trong bài lab. Sau đó chọn Delete . Nhập tên role RoleLab2. Sau đó chọn Delete. Access Keys Tại trang console, chúng ta chọn tên tài khoản ở góc trên bên phải. Sau đó chọn Security credentials. Chọn Access Key đã khởi tạo trong bài lab. Sau đó chọn Action \u0026ndash;\u0026gt; Delete Chọn Deactivate. Nhập tên Access Key và chọn Delete Vậy là chúng ta đã dọn dẹp tất cả tài nguyên trong workshop này. Cảm ơn mọi người đã quan tâm và theo dõi.\n"
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]